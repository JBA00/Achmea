import pandas as pd
import matplotlib.pyplot as plt
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans


def create_df(what_for="clustering"):
    # Create the data frames
    erasmus_db = pd.read_csv("Erasmus.csv", sep=";")
    mutation_log_db = pd.read_csv("Mutatielog_id.csv", sep=";")
    toelichting_db = pd.read_excel("Toelichting.xlsx")

    # Create new columns for date and time
    mutation_log_db['DatumRegistratie'] = pd.to_datetime(
        mutation_log_db['DatumRegistratie'])

    mutation_log_db['date'] = mutation_log_db['DatumRegistratie'].dt.date
    mutation_log_db['time'] = mutation_log_db['DatumRegistratie'].dt.time

    # Fix float values.
    for col in erasmus_db.columns:
        try:
            erasmus_db[col] = erasmus_db[col].str.replace(
                ',', '.').astype(float)
        except Exception:
            continue

    # Translate the column into lists, so that maybe we can calculate the number of red flags.
    erasmus_db['SF_woord'] = erasmus_db['SF_woord'].str.replace(
        ' ', '').str.split(',')

    erasmus_db['SF_woord_count'] = [len(x) if isinstance(
        x, list) else None for x in erasmus_db['SF_woord']]

    if what_for == "random_forest":
        erasmus_db = erasmus_db.drop("SF_woord", axis=1).drop(
            "id", axis=1).drop("prediction", axis=1)

    erasmus_db["SF_woord_count"].fillna(0, inplace=True)

    # Here are some assumptions about are made, to replace null values- probs better to discuss.
    erasmus_db["woord_74"].fillna(0, inplace=True)
    erasmus_db["woord_121"].fillna(0, inplace=True)

    erasmus_db["D_LG4_1j"].fillna(0, inplace=True)
    erasmus_db["D_cat_1g"].fillna(0, inplace=True)
    erasmus_db["D_cat_4b"].fillna(0, inplace=True)

    erasmus_db["VT_cat_1b"].fillna(999, inplace=True)
    erasmus_db["VT_cat_1d"].fillna(999, inplace=True)
    erasmus_db["VT_cat_1g"].fillna(999, inplace=True)
    erasmus_db["VT_cat_2c"].fillna(999, inplace=True)
    erasmus_db["VT_cat_4b"].fillna(999, inplace=True)
    erasmus_db["VT_cat_5e"].fillna(999, inplace=True)
    erasmus_db["VT_cat_8a"].fillna(999, inplace=True)
    erasmus_db["VT_cat_9a"].fillna(999, inplace=True)
    erasmus_db["VT_cat_10b"].fillna(999, inplace=True)
    erasmus_db["VT_cat_10g.2"].fillna(999, inplace=True)

    if what_for == "eda":
        erasmus_db = erasmus_db[["vm", "polis_2", "polis_5",
                                 "age", "status", "LG1", "SF_woord_count"]]
    if what_for=="clustering":
        erasmus_db = erasmus_db.drop(["SF_woord", "id", "prediction"], axis=1)    

    return erasmus_db


# Clustering
df_clustering = create_df("clustering")
print(df_clustering)


# Create dummy variables for status
df_clustering = pd.get_dummies(df_clustering, columns=['status'])
print(df_clustering.head())

# Create bolean values for VT Features
columns_to_replace = ['VT_LG3_2_1', 'VT_LG4_1a', 'VT_LG4_1d', 'VT_LG4_1e', 'VT_LG4_1b',
       'VT_LG2_2_2', 'VT_cat_1b', 'VT_cat_1d', 'VT_cat_1g', 'VT_cat_1he',
       'VT_cat_2a', 'VT_cat_2b', 'VT_cat_2c', 'VT_cat_2f', 'VT_cat_2k',
       'VT_cat_3b', 'VT_cat_3e', 'VT_cat_4a', 'VT_cat_4b', 'VT_cat_4f',
       'VT_cat_4hd', 'VT_cat_4he', 'VT_cat_5e', 'VT_cat_5gc', 'VT_cat_6b',
       'VT_cat_7a', 'VT_cat_8a', 'VT_cat_9a', 'VT_cat_10a', 'VT_cat_10b',
       'VT_cat_10c', 'VT_cat_10f', 'VT_cat_10g', 'VT_cat_10g.1',
       'VT_cat_10g.2', 'VT_cat_10g.3', 'VT_cat_10g.4', 'VT_cat_11d',
       'VT_EV_1_1', 'VT_EV_2_1', 'VT_EV_3_1', 'VT_EV_4_1', 'VT_EV_6_1',
       'VT_EV_7_1_3', 'VT_EV_8_1_3']

# Replace "999" with False and all other values with True
df_clustering[columns_to_replace] = df_clustering[columns_to_replace] == '999'
print(df_clustering.head())

#find numerical, and boolean features 
numerical_features = df_clustering.select_dtypes(include=['int64', 'float64']).columns
boolean_features = df_clustering.select_dtypes(include=['bool']).columns
print(numerical_features)
print(boolean_features)

# Turn Boolean features to binary
def binary_transform(value, desired_value=True):
    return 1 if value == desired_value else 0

df_clustering[boolean_features] = df_clustering[boolean_features].applymap(binary_transform)
print(df_clustering)

# Exclude vm and sf from numerical features 
features_to_exclude = ['vm', 'SF']
numerical_features = numerical_features.difference(features_to_exclude)

# Normalize numerical features
scaler = MinMaxScaler()
df_clustering[numerical_features] = scaler.fit_transform(df_clustering[numerical_features])


# Cluster and find centroids for all features
num_clusters = 2
kmeans = KMeans(n_clusters=num_clusters, random_state=1234)
df_clustering['cluster_label'] = kmeans.fit_predict(df_clustering)

centroids = kmeans.cluster_centers_
centroids_df = pd.DataFrame(centroids, columns=df_clustering.columns[:-1])
print(centroids_df)

# top 5 features
for cluster_label in range(num_clusters):
    print(f"\nCluster {cluster_label + 1} Features with Biggest Effect:")
    
    
    abs_centroids = abs(centroids_df.loc[cluster_label, :])
    
   
    sorted_features = abs_centroids.sort_values(ascending=False)
    
    
    top_features = sorted_features.index[:5]  
    for feature in top_features:
        feature_value = centroids_df.loc[cluster_label, feature]
        print(f"- {feature}: {feature_value}")

# Heat map for clusters
# Data for Cluster 1
cluster1_data = {
    'EV_6': 0.9861539818326202,
    'EV_3': 0.9481435752711952,
    'EV_8': 0.9236264220830628,
    'cat_1i': 0.9039597848134905,
    'cat_4i': 0.8896728106534944,
}

# Data for Cluster 2
cluster2_data = {
    'cat_4i': 0.972566894572463,
    'cat_1i': 0.9651388537182375,
    'cat_8h': 0.9518021440026982,
    'cat_6g': 0.9481725331307553,
    'cat_7f': 0.9381277960665121,
}

# Create a DataFrame
df_cluster2 = pd.DataFrame(list(cluster2_data.items()), columns=['Features', 'Cluster 2'])
df_cluster1 = pd.DataFrame(list(cluster1_data.items()), columns=['Features', 'Cluster 1'])


# Pivot the data for heatmap
heatmap_data = pd.concat([df_cluster1.set_index('Features'), df_cluster2.set_index('Features')], axis=1).T

# Create the heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(heatmap_data, cmap='viridis', annot=True, fmt=".3f", linewidths=.5)
plt.title('Feature Effects in Clusters')
plt.show()



